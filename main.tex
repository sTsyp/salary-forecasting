\documentclass{article}
\usepackage[english, russian]{babel}
\usepackage[letterpaper,top=1cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=red]{hyperref}
\usepackage[usename]{color}
\usepackage{xcolor}
\usepackage[dvipsnames]{xcolor}

\documentclass[14pt, a4paper]{article}


\color{black}
\title{Отчёт о проделанной работе по теме "Прогнозирование зарплатных ожиданий соискателей с помощью методов машинного обучения"}
\author{Карнаушенко Михаил \\ Цыплаков Александр}

\begin{document}
\pagecolor{white}
%\input{frontpage.tex}
\begin{center}
\noindent Правительство Российской Федерации Федеральное государственное автономное образовательное учреждение высшего образования\\

Национальный исследовательский университет\\
«Высшая школа экономики»\bigskip\\

Образовательная программа «Прикладная математика»\\
\vfill
\bigskip
\bigskip
\begin{Large} \text{Отчет}\\
\text{по проектной работе}\\
\end{Large}
\\
\\
\bigskip
\begin{Large}
\textbf{Прогнозирование зарплатных ожиданий соискателей с помощью методов машинного обучения}
\end{Large}
\vfill
\vfill
\begin{flushright}

Карнаушенко Михаил\\
Цыплаков Александр\bigskip\\
                       

\end{flushright}
\vfill
\begin{center}
\textbf{Москва 2022}
\end{center}

\end{center}
\pagebreak


\maketitle







\section{Введение}

\subsection{Актуальность}
Интеллектуальная система, представленная в данном проекте, значительно упрощает работу по поиску сотрудников для различных компаний, ровно как и наоборот, помогает кандидатам при выборе вакансий. Такая система основывает свой поиск на независимой оценке способностей, а также делает упор на умение работать с большим количеством данных. 


\subsection{Практическое применение}
Данный проект носит как теоретический, с точки зрения получаемых знаний и статистического анализа, так и практический характер, буквально помогающий получать данные о зарплатных ожиданиях. 
 

\section{Цель}
 Научиться применять знания о машинном обучении на практике.\\ Научиться собирать и анализировать данные для интеллектуальных моделей.\\ Научиться прогнозировать зарплатные ожидания соискателей с помощью машинного обучения.

\bigskip
\section{Задачи}
\begin{itemize}
  \color{red}
  \item \color{black} Сбор данных.
    \color{red}
  \item \color{black} Обработка данных.
  \color{red}
  \item \color{black} Обучение модели.
  \color{red}
  \item \color{black} Оценка качества работы и сравнение результатов.

  
\end{itemize}

\section{Ход работы над проектом}

\subsection{Сбор данных}
\color{black}
Мы решили собирать данные с сайта hh.ru\cite{WEBSITE:1} - популярного в России сервиса для поиска работы и сотрудников. Рассматривались и другие варианты, но мы посчитали, что этот сайт наиболее удобен для сбора информации. Поскольку данные анализировать целесообразно по одной категории, то мы выбрали одну из популярных и актуальных сфер, такую как 'IT-специалист'.
Для этого в графе поиска на сайте выберем интересующую нас профессию и выставим фильтры так, чтобы как можно больше категорий отображалось в резюме. 


По-скольку получать данные вручную было бы крайне долго, то нами был выбран вариант парсинга данных с сайта. 
Парсинг - это автоматизированный сбор информации с веб-ресурса. В нашем случае, все программы для этих целей мы писали на языке программирования Python, поскольку он обладает большим количеством библиотек, подходящих для данной задачи\cite{WEBSITE:2}.
Основные библиотеки, используемые нами:
\begin{itemize}
  \color{red}
  \item \color{black} requests
  \color{red}
  \item \color{black} selenium
  \color{red}
  \item \color{black} BeautifulSoup
  \color{red}
  \item \color{black} fake-useragent
  \color{red}
  \item \color{black} lxml
  \color{red}
  \item \color{black} NumPy
  \color{red}
  \item \color{black} sklearn
   \color{red}
  \item \color{black} matpotlib
   \color{red}
  \item \color{black} Pandas
\end{itemize}

Каждая библиотека отвечает за определенный этап парсинга. Библиотека requests отправляет запрос на сайт, как если бы это делал человек. Но, как правило, сайты не любят, когда на них отправляется много запросов за короткий промежуток времени. Именно поэтому мы подключили еще одну библиотеку fake-useragent, которая генерирует фейковые user-agent (буквально маски, под которыми мы заходим в интернет). Тем самым сайт больше не блокирует наш поток запросов. 
Дальнейшая проблема, с которой мы столкнулись - динамический сайт. То есть, при открытии страницы, ее содержимое появляется и становится видимым для "считывания" HTML-кодом только после прокрутки пользователем страницы вниз. Для этой цели мы подключаем библиотеку selenium, способную работать с пользовательским интерфейсом. Порядок выполнения таков:

Запрос отправляется на сайт -> selenium прокручивает страницу до ее конца -> HTML-код сохраняется к нам в архив\\

\color{black}

hh.ru предлагает услуги предоставления всей своей базы данных платно, поэтому мы ограничились 5000 резюме для общего доступа. 
Структура сайта такова, что происходит прогрузка страницы по 100 резюме в кратком виде, таким образом нам было доступно 50 страниц с 100 резюме на странице. Каждое резюме не имело достаточной инфомации, но имело ссылку на полное резюме. Поэтому дальше мы подключили библиотеку BeautifulSoup , которая открывала по очереди все 5000 резюме и сохраняла код страницы. Дальше с помощью парсера lxml и BeautifulSoup мы собирали данные с каждого резюме. 

\subsection{Обработка данных}
Изначально нам показалось, что данных для обучения модели будет недостаточно, так как для каждого из 5000 объектов находилось не больше 10 признаков. С этой проблемой мы начали искать готовые данные по нашей теме, но нашли лишь базы с меньшим количеством признаков, чем у нас. 
Было принято решение собирать все имеющиеся данные, указанные в резюме. 

\begin{itemize}
  \color{red}
  \item \color{black} wage - заработная плата, то есть тот показатель, который мы хотим получать как ответ на нашу задачу.
  \color{red}
  \item \color{black} age - возраст соискателя. 
  \color{red}
  \item \color{black} exp - опыт работы соискателя в годах.
  \color{red}
  \item \color{black} sex - пол соискателя 
  \color{red}
  \item \color{black} bachelor - высшее образование
  \color{red}
  \item \color{black} special education - колледж
  \color{red}
  \item \color{black} courses - факт прохождения курсов повышения квалификации
  \color{red}
  \item \color{black} English - знание языка 
  \color{red}
  \item \color{black} driver license - наличие водительских прав
  \color{red}
  \item \color{black} private car - наличие собственной машины
  \color{red}
  \item \color{black} business trip - готовность к командировкам
  \color{red}
  \item \color{black} relocate - готовность к переезду
  \color{red}
  \item \color{black} travel time - требование к времени на дорогу
  \color{red}
  \item \color{black} skills - навыки соискателя

\end{itemize}
\color{black}

Среди полученных данных присутсвуют как численные значения (то есть интервальные признаки), так и категориальные признаки, отвечающие за принадлежность объекта к тому или иному классу. То есть, например, признак exp - интервальный, а sex - категориальный. Так как компьютер способен обрабатывать только числа, то был применен метод One-Hot-Encoding\cite{WEBSITE:3}, который разбивает признак на внутренние подпризнаки, формируя матрицы. То есть признак English будет выглядть как вектор:
\begin{center}
    

English = 
\begin{pmatrix}
A1 \\ A2 \\ B1 \\ B2 \\ C1 \\ C2
\end{pmatrix}
\end{center}
Здесь каждая строка в вектор-столбце отвечает за определенный уровень владения английским языком и принимает значение 0 или 1. 
\bigskip
Также, после получения всех данных, мы можем их нормировать, то есть привести к какому-то диапазону значений. Это необходимо, чтобы значения, имеющие большой показатель отклонения от стандратной величины не портили точность прогнозов. Такое действие не обязательно для всех моделей, но для некоторых важно. Точность можно оценивать, используя метрики. 


\subsubsection{Обучение Модели}
Так как мы хотим прогнозировать зарплатные ожидания, то нами была выбрала регрессионная модель обучения, которая дает на выходе численный ответ - зарплату, на которую мог бы расчитывать соискатель. Для этих целей мы выбрали 2 модели, которые будем обучать и сравнивать результаты работы:
\begin{itemize}
  \color{red}
  \item \color{black} Линейная регрессия
  \color{red}
  \item \color{black} Случаный лес
\end{itemize}
Подробнее про принцип работы всех двух моделей будет написано далее.
При первой попытке написания модели линейной регрессии мы столкнулись с серьезной проблемой\\
Она заключалась в том, что построение линейной регрессии больше подходит для интервальных переменных, а не категориальных, то есть на графике рассеивания зарплаты от опыта работы(или возраста), располагаются точки (люди), а далее проводится прямая, которая будет проходить через центр этого облака. Таких переменных было всего две: возраст и стаж работы, но, как оказалось далее, корреляция между зарплатой и одним из этих признаков слишком мала для построения точной модели, к тому же возникла \textbf{мультиколлинеарность} между этими двумя предикторами, то есть независимые переменные очень сильно коррелировали между собой.\\ 
\begin{center}
    

\includegraphics[scale=0.4]{Снимок экрана 2022-05-23 в 21.07.28.jpg}\\
Корреляция между зарплатой, стажем работы и возрастом.\\
\end{center}
\begin{center}
    

\includegraphics[scale=0.3]{Снимок экрана 2022-05-23 в 21.03.40.jpg}\\
График рассеивания между зарплатой и опытом работы.\\
\end{center}


Как раз из-за мультиколлинеарности и возникла проблема построения модели по этим данным. Именно по этому было принято решение построить модель по категориальным данным, используя \textbf{Ridge} регрессию, о которой будет написано далее. После построения модели по такому принципу, метрика \(R^2\), которая также будет описана позже, была равна 0.12, что, естественно, не удовлетворяет нашим требованиям. Поэтому мы вернулись к изначальному датасету и стали вручную анализировать данные и пришли к выводу, что люди по большей части указывали зарплату вне зависимости от собственных навыков, то есть, к примеру, у человека слишком завышенная зарплата, а особые навыки отсутствуют, и наоборот. В следствие этого нам пришлось отказаться от собранного датасета.
\subsubsection{Сбор новых данных и их обработка}
  


Так как наши данные не прошли проверку на пригодность, мы решили собрать новые. Повторив уже существующую схему парсинга, мы собрали еще несколько датасетов, но уже для других отраслей, и с других сайтов\cite{WEBSITE:10}. Но эти датасеты вновь не превысили минимальных ожиданий. Именно поэтому, за неимением других вариантов, мы решили взять готовый датасет. Наш выбор пал на данные с сайта предоставляющего большое количество уже собранных данных\cite{WEBSITE:4}.

Поскольку тема проекта - прогнозирование зарплатных ожиданий, то мы решили взять таблицу с информацией о 14447 работниках институтов, для каждого из которых указаны такие данные: имя, должность, зарплата, отдел и название колледжа.\\
\begin{center}
\includegraphics[scale=0.45]{output_density_salaries.png}\\
График зависимости зарплаты от количества человек\\
\end{center}
Очевидно, что зарплата от имени никак не зависит, поэтому мы смело можем удалить этот столбец из датасета, не боясь, что это как-то повлияет на нашу точность.\\

С помощью One-Hot-Encoding\cite{WEBSITE:4}, встроенного в sklearn кодируем все категориальные признаки, которые у нас есть. Причем также считается количество вхождений закодированного слова(то есть его частота появлений, которая может быть показателем для возможности устранения из датасета). После кодировки получаем такое разбиение: столбец с должностью разбивается на 147 закодированных колонок, каждая колонка является определенной должностью и принимает значение либо 1, либо 0; столбец с отделом в колледже разбивается на 109 закодированных, по такому же принципу, колонок; столбец с колледжем разбивается на 12 закодированных колонок соответственно.

\subsection{Обучение модели}

Две модели, которые мы будем использовать отличаются по своей структре.

\begin{itemize}
   \color{red} \item \color{black} Линейная регрессия (Ridge)
\end{itemize}

Так как мы уже выяснили, что предыдущий датасет не подошел нам, то мы решили использовать линейную регрессию с L2 регуляризатором, или линейную регрессию типа ridge\cite{WEBSITE:5}. Ее особенность заключается в том, что она сглаживает неравентсво весов коэффициентов у признаков. Формульно ее можно задать так:
\[(y - wX)^2 + \lambda \sum {}{}w_i ^ 2 \rightarrow min \]
В отличие от обычной линейной регрессии без регуляризации:
\[(y - wX)^2  \rightarrow min \]
Здесь y, Х задают целевую переменную и матрицу признаков, а w - их веса, то есть коэффициенты. А в общем уравнение отвечает методу наименьших квадратов (МНК).

\begin{itemize}
   \color{red} \item \color{black} Случайный лес 
\end{itemize}
Случайный лес\cite{WEBSITE:6}- предсказательная модель, строящая множество деревьев решений и выдающая средний результат. Дерево решений - дерево, которое в каждом своем узле содержит условное выражение, делящее выборку. Такая модель очень хорошо дает прогнозы, но плохо расставляет закономерности. То есть нет такого явного набора коэффициентов, как в случае с линейной регрессией. 

Теперь, когда мы окончатльно определились с моделями, мы можем начать процесс обучения. 
Для этого нам понадобится по большей части библиотека sklearn в python:

sklearn.preprocessing: OneHotEncoder

sklearn.compose: ColumnTransformer


sklearn.pipeline: Pipeline


sklearn.model\_selection: KFold

sklearn.linear\_model: Ridge


sklearn.ensemble: RandomForestRegressor\\

Для обучения данные делятся на тренировочную и тестовую выборку. Соотвественно, модель учится предсказывать на тренировочных данных, и делает предсказания на тестовых. Но возникает проблема - так как данные могут различаться и быть упорядочены, то модель, учившаяся на одних значениях, будет плохо работать на других. Для этого существует кросс-валидация, которая  делит их на несколько частей, поочердено выбирая их как тестовые и тренировочные. Предварительно мы специально перемешиваем данные, чтобы избежать какой-либо упорядоченности в датасете. После этого предсказания усредняются, что позволяет нам сравнивать результаты работы разных моделей. 
Мы использовали деление на 3, 5, 10 и 20 частей. Чем больше было количество разбиений - тем выше становилась точность, но повышать количество разбиейний до слишком высоких значений уже сложнее - не хватает вычислительных мощностей. Вот несколько примеров работы моделей:\\

\includegraphics[scale = 0.4]{beuty_corr.png}\\
Здесь по горизонатали указаны люди, а по вертикали - их зарплаты. Голубым цветом отмечены истинные тестовые данные, красным - прогнозы линейной регрессии.


\includegraphics[scale = 0.4]{rf_graf.png}\\
Здесь по горизонатали указаны люди, а по вертикали - их зарплаты. Зеленым цветом отмечены истинные тестовые данные, красным - прогнозы случайного леса.

Мы написали функцию, которая выводит тончость модели, и запустили ее для всех наших моделей. Получив результат, мы можем переходить к выводам.
\subsubsection{Метрики}
Мы использовали три метрики\cite{book:11}:
\begin{itemize}
     \color{red} \item \color{black} MAPE
     \color{red} \item \color{black} RMSE
     \color{red} \item \color{black} \(R^2 \)
\end{itemize}
\textit{MAPE} - Mean absolute percentage error regression loss\cite{WEBSITE:7}, средняя абсолютная процентная потеря регрессии. Показывает на сколько велики ошибки в сравнении со значениями ряда. Вычисляется по формуле: 
\begin{equation}
    MAPE = \frac{1}{n}{\sum\frac{ |Ytest - Ypred|
    }{Ytest}}
\end{equation}
Здесь Ytest - тестовые значения из выборки, \\ Ypred - значения предсказаний, \\n- количество значений в выборке. 
\bigskip

\textit{RMSE} - Root Mean Squared Error\cite{WEBSITE:8}, то есть среднеквадратичная ошибка. Показывает то, насколько в среднем отклоняется величина от среднего значения. Вычисляется по формуле: 
\begin{equation}
    RMSE = \sqrt{\frac{\sum (Ytest - Ypred)^2 }{N}}
\end{equation}
Здесь Ytest - тестовые значения из выборки, \\ Ypred - значения предсказаний, \\N- количество значений в выборке. 
Чем меньше это число, тем больше точность нашей модели.
\bigskip

\textit{$R^2$} - обозначает коэффициент детерминированности (R-Squared\cite{WEBSITE:9}) и выражается формулой:
\begin{equation}
    R^2 = 1 - \frac{\sum (Ytest - Ypred) ^2}{(\sum Ytest - Yavg )^2}
\end{equation}
Здесь Ytest - тестовые значения из выборки,\\ Ypred - значения предсказаний, \\ Yavg - среднее значение из тестовой выборки. Чем больше значение \(R^2 \) к числу 1, тем больше точность нашей модели. 





Все формулы для подсчета метрик уже есть в качестве встроенных функций библиотеки sklearn. 

\subsection{Результаты}
Для всех моделей приведем полученные результаты метрик.


\begin{center}
    

\begin{tabular}{ | l | l | l | l | l |}
\hline
Модель & MAPE  & RMSE & $R^2$ \\ \hline
Линейная регрессия & 0.420 & 133.00 ± 1.40 & 0.638 ± 0.012\\ \hline
Случайный лес & 0.320 & 123.97 ± 1.57 & 0.626 ± 0.013\\ \hline

\hline
\end{tabular}

\end{center}

\section{Выводы}
Анализируя полученные результаты, мы можем придти к выводу, что стандартное отклонение метрики RMSE для линейной регрессии и случайного леса очень близки, в то время как абсолютное значение этой метрики для двух моделей отличается примерно на 7\%. Значение же метрики MAPE меньше для модели случайного леса, то есть он выдает более точный результат. Исходя из этого можно сделать вывод о том, что предсказания случаного леса подходят для нашей задачи наилучшим образом. Дело в том, что случайный лес более аккуратно учитывает категориальные признаки. Точность(\(R^2\)) при различных значениях разбиений для кросс-валидации достигла значения, близкого к 64\%.
Таким образом мы научились собирать данные для интеллектуальных моделей, научились их правильно фильтровать и строить на их основании модели, принцип которых мы понимаем. 

\section{Распределение обязанностей группового проекта}
\\
\begin{itemize}
     \color{red} \item \color{black} Первая сборка
\end{itemize}
\begin{center}
\begin{tabular}{ | l | l | l | l | l |}
\hline
Михаил & Александр \\ \hline
Парсинг данных с сайта hh.ru & Парсинг данных с сайта работа.ru\\ \hline
Обучение модели случайного леса  & Обучение модели линейной регрессии\\ \hline
Расчёт метрики RMSE, $R^2$ и MAPE & Расчёт метрики RMSE, $R^2$ и MAPE\\ 
для случайного леса  & для линейной регрессии\\ 
\hline
\end{tabular}
\end{center}

\begin{itemize}
     \color{red} \item \color{black} Вторая сборка
\end{itemize}
\begin{center}
\begin{tabular}{ | l | l | l | l | l |}
\hline
Михаил & Александр \\ \hline
Обучение модели случайного леса  & Обучение модели линейной регрессии\\ \hline
Расчёт метрики RMSE, $R^2$ и MAPE & Расчёт метрики RMSE, $R^2$ и MAPE\\ 
для случайного леса  & для линейной регрессии\\ 
\hline
\end{tabular}
\end{center}
\bibliography{sample} 
\bibliographystyle{abbrv}

\end{document}

